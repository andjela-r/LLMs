{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d095a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import AssistantAgent, UserProxyAgent\n",
    "from autogen.oai.openai_utils import config_list_from_json\n",
    "from types import SimpleNamespace\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModelClient:\n",
    "    def __init__(self, config, **kwargs):\n",
    "        print(f\"CustomModelClient config: {config}\")\n",
    "        self.api_key = config.get(\"api_key\")\n",
    "        self.api_url = \"http://localhost:8000/generate\"\n",
    "        self.model = config.get(\"model\", \"gpt-3.5-turbo\")\n",
    "        self.max_tokens = config.get(\"max_tokens\", 4000)\n",
    "        self.temperature = config.get(\"temperature\", 0.8)\n",
    "        self.top_p = config.get(\"top_p\", 1)\n",
    "        self.presence_penalty = config.get(\"presence_penalty\", 1)\n",
    "\n",
    "        print(f\"Initialized CustomModelClient with model {self.model}\")\n",
    "\n",
    "    def create(self, params):\n",
    "\n",
    "        messages = params.get(\"messages\", [])\n",
    "        if isinstance(messages, list):\n",
    "            prompt = \"\\n\".join([m.get(\"content\", \"\") for m in messages if m.get(\"role\") in (\"user\", \"system\")])\n",
    "        else:\n",
    "            prompt = str(messages)\n",
    "\n",
    "        data = {\n",
    "            \"max_tokens\": self.max_tokens if self.max_tokens else 4000,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p if self.top_p else 0.9,\n",
    "            \"prompt\": prompt,\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.api_url, json=data)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        api_response = response.json()\n",
    "        print(api_response)\n",
    "        # Convert API response to SimpleNamespace for compatibility\n",
    "        client_response = SimpleNamespace()\n",
    "        client_response.choices = []\n",
    "        client_response.model = self.model\n",
    "\n",
    "        for choice in api_response.get(\"choices\", []):\n",
    "            client_choice = SimpleNamespace()\n",
    "            client_choice.message = SimpleNamespace()\n",
    "            client_choice.message.content = choice.get(\"message\", {}).get(\"content\")\n",
    "            client_choice.message.function_call = None\n",
    "            client_response.choices.append(client_choice)\n",
    "\n",
    "        return client_response\n",
    "\n",
    "    def message_retrieval(self, response):\n",
    "        \"\"\"Retrieve the messages from the response.\"\"\"\n",
    "        choices = response.choices\n",
    "        return [choice.message.content for choice in choices]\n",
    "\n",
    "    def cost(self, response) -> float:\n",
    "        \"\"\"Calculate the cost of the response.\"\"\"\n",
    "        # Implement cost calculation if available from your API\n",
    "        response.cost = 0\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def get_usage(response):\n",
    "        # Implement usage tracking if available from your API\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9286c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_custom = config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST.json\",\n",
    "    filter_dict={\"model_client_cls\": [\"CustomModelClient\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c216bd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'Qwen/Qwen3-0.6B', 'model_client_cls': 'CustomModelClient'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 05-20 11:08:45] {871} INFO - Detected custom model client in config: CustomModelClient, model client can not be used until register_model_client is called.\n",
      "CustomModelClient config: OpenAILLMConfigEntry(api_type='openai', model='Qwen/Qwen3-0.6B', model_client_cls='CustomModelClient', tags=[])\n",
      "Initialized CustomModelClient with model Qwen/Qwen3-0.6B\n"
     ]
    }
   ],
   "source": [
    "assistant = AssistantAgent(name=\"assistant\", llm_config={\"config_list\": config_list_custom})\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    code_execution_config={\n",
    "        #\"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "assistant.register_model_client(model_client_cls=CustomModelClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f25366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What is the tallest building in the world?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{'choices': [{'message': {'content': 'The tallest building in the world is the Burj Khalifa in Dubai, UAE. This building stands at 828 meters and is the tallest in the world. \\n\\nTERMINATE'}}]}\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The tallest building in the world is the Burj Khalifa in Dubai, UAE. This building stands at 828 meters and is the tallest in the world. \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (857adda9-40d0-45c9-a671-5b85e2d0ec27): User requested to end the conversation\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What is the tallest building in the world?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'The tallest building in the world is the Burj Khalifa in Dubai, UAE. This building stands at 828 meters and is the tallest in the world. \\n\\nTERMINATE', 'role': 'user', 'name': 'assistant'}], summary='The tallest building in the world is the Burj Khalifa in Dubai, UAE. This building stands at 828 meters and is the tallest in the world. \\n\\n', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['exit'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What is the tallest building in the world?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ebad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
