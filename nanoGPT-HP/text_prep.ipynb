{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8e8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0c766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('andjela-r/mlm-harry-potter', split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1a2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab0b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29224fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding='utf-8') as file:\n",
    "    for line in data[\"text\"]:\n",
    "        file.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f4f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0117669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characers:  6235521\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characers: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087502fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere.\n",
      "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Pot\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "768e384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001f !\"#$%&'()*,-./0123456789:;=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{}~­éü\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147005aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple tokenizer - character level\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30ee8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 72, 72, 2, 83, 71, 68, 81, 68]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hi there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d0e577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6235521]) torch.int64\n",
      "tensor([39, 64, 81, 81, 88,  2, 47, 78, 83, 83, 68, 81,  2, 64, 77, 67,  2, 83,\n",
      "        71, 68,  2, 50, 78, 81, 66, 68, 81, 68, 81,  9, 82,  2, 50, 83, 78, 77,\n",
      "        68,  0, 34, 39, 32, 47, 51, 36, 49,  2, 46, 45, 36,  0, 51, 39, 36,  2,\n",
      "        33, 46, 56,  2, 54, 39, 46,  2, 43, 40, 53, 36, 35,  0, 44, 81, 15,  2,\n",
      "        64, 77, 67,  2, 44, 81, 82, 15,  2, 35, 84, 81, 82, 75, 68, 88, 13,  2,\n",
      "        78, 69,  2, 77, 84, 76, 65, 68, 81,  2, 69, 78, 84, 81, 13,  2, 47, 81,\n",
      "        72, 85, 68, 83,  2, 35, 81, 72, 85, 68, 13,  2, 86, 68, 81, 68,  2, 79,\n",
      "        81, 78, 84, 67,  2, 83, 78,  2, 82, 64, 88,  2, 83, 71, 64, 83,  2, 83,\n",
      "        71, 68, 88,  2, 86, 68, 81, 68,  2, 79, 68, 81, 69, 68, 66, 83, 75, 88,\n",
      "         2, 77, 78, 81, 76, 64, 75, 13,  2, 83, 71, 64, 77, 74,  2, 88, 78, 84,\n",
      "         2, 85, 68, 81, 88,  2, 76, 84, 66, 71, 15,  2, 51, 71, 68, 88,  2, 86,\n",
      "        68, 81, 68,  2, 83, 71, 68,  2, 75, 64, 82, 83,  2, 79, 68, 78, 79, 75,\n",
      "        68,  2, 88, 78, 84,  9, 67,  2, 68, 87, 79, 68, 66, 83,  2, 83, 78,  2,\n",
      "        65, 68,  2, 72, 77, 85, 78, 75, 85, 68, 67,  2, 72, 77,  2, 64, 77, 88,\n",
      "        83, 71, 72, 77, 70,  2, 82, 83, 81, 64, 77, 70, 68,  2, 78, 81,  2, 76,\n",
      "        88, 82, 83, 68, 81, 72, 78, 84, 82, 13,  2, 65, 68, 66, 64, 84, 82, 68,\n",
      "         2, 83, 71, 68, 88,  2, 73, 84, 82, 83,  2, 67, 72, 67, 77,  9, 83,  2,\n",
      "        71, 78, 75, 67,  2, 86, 72, 83, 71,  2, 82, 84, 66, 71,  2, 77, 78, 77,\n",
      "        82, 68, 77, 82, 68, 15,  0, 44, 81, 15,  2, 35, 84, 81, 82, 75, 68, 88,\n",
      "         2, 86, 64, 82,  2, 83, 71, 68,  2, 67, 72, 81, 68, 66, 83, 78, 81,  2,\n",
      "        78, 69,  2, 64,  2, 69, 72, 81, 76,  2, 66, 64, 75, 75, 68, 67,  2, 38,\n",
      "        81, 84, 77, 77, 72, 77, 70, 82, 13,  2, 86, 71, 72, 66, 71,  2, 76, 64,\n",
      "        67, 68,  2, 67, 81, 72, 75, 75, 82, 15,  2, 39, 68,  2, 86, 64, 82,  2,\n",
      "        64,  2, 65, 72, 70, 13,  2, 65, 68, 68, 69, 88,  2, 76, 64, 77,  2, 86,\n",
      "        72, 83, 71,  2, 71, 64, 81, 67, 75, 88,  2, 64, 77, 88,  2, 77, 68, 66,\n",
      "        74, 13,  2, 64, 75, 83, 71, 78, 84, 70, 71,  2, 71, 68,  2, 67, 72, 67,\n",
      "         2, 71, 64, 85, 68,  2, 64,  2, 85, 68, 81, 88,  2, 75, 64, 81, 70, 68,\n",
      "         2, 76, 84, 82, 83, 64, 66, 71, 68, 15,  2, 44, 81, 82, 15,  2, 35, 84,\n",
      "        81, 82, 75, 68, 88,  2, 86, 64, 82,  2, 83, 71, 72, 77,  2, 64, 77, 67,\n",
      "         2, 65, 75, 78, 77, 67, 68,  2, 64, 77, 67,  2, 71, 64, 67,  2, 77, 68,\n",
      "        64, 81, 75, 88,  2, 83, 86, 72, 66, 68,  2, 83, 71, 68,  2, 84, 82, 84,\n",
      "        64, 75,  2, 64, 76, 78, 84, 77, 83,  2, 78, 69,  2, 77, 68, 66, 74, 13,\n",
      "         2, 86, 71, 72, 66, 71,  2, 66, 64, 76, 68,  2, 72, 77,  2, 85, 68, 81,\n",
      "        88,  2, 84, 82, 68, 69, 84, 75,  2, 64, 82,  2, 82, 71, 68,  2, 82, 79,\n",
      "        68, 77, 83,  2, 82, 78,  2, 76, 84, 66, 71,  2, 78, 69,  2, 71, 68, 81,\n",
      "         2, 83, 72, 76, 68,  2, 66, 81, 64, 77, 72, 77, 70,  2, 78, 85, 68, 81,\n",
      "         2, 70, 64, 81, 67, 68, 77,  2, 69, 68, 77, 66, 68, 82, 13,  2, 82, 79,\n",
      "        88, 72, 77, 70,  2, 78, 77,  2, 83, 71, 68,  2, 77, 68, 72, 70, 71, 65,\n",
      "        78, 81, 82, 15,  2, 51, 71, 68,  2, 35, 84, 81, 82, 75, 68, 88, 82,  2,\n",
      "        71, 64, 67,  2, 64,  2, 82, 76, 64, 75, 75,  2, 82, 78, 77,  2, 66, 64,\n",
      "        75, 75, 68, 67,  2, 35, 84, 67, 75, 68, 88,  2, 64, 77, 67,  2, 72, 77,\n",
      "         2, 83, 71, 68, 72, 81,  2, 78, 79, 72, 77, 72, 78, 77,  2, 83, 71, 68,\n",
      "        81, 68,  2, 86, 64, 82,  2, 77, 78,  2, 69, 72, 77, 68, 81,  2, 65, 78,\n",
      "        88,  2, 64, 77, 88, 86, 71, 68, 81, 68, 15,  0, 51, 71, 68,  2, 35, 84,\n",
      "        81, 82, 75, 68, 88, 82,  2, 71, 64, 67,  2, 68, 85, 68, 81, 88, 83, 71,\n",
      "        72, 77, 70,  2, 83, 71, 68, 88,  2, 86, 64, 77, 83, 68, 67, 13,  2, 65,\n",
      "        84, 83,  2, 83, 71, 68, 88,  2, 64, 75, 82, 78,  2, 71, 64, 67,  2, 64,\n",
      "         2, 82, 68, 66, 81, 68, 83, 13,  2, 64, 77, 67,  2, 83, 71, 68, 72, 81,\n",
      "         2, 70, 81, 68, 64, 83, 68, 82, 83,  2, 69, 68, 64, 81,  2, 86, 64, 82,\n",
      "         2, 83, 71, 64, 83,  2, 82, 78, 76, 68, 65, 78, 67, 88,  2, 86, 78, 84,\n",
      "        75, 67,  2, 67, 72, 82, 66, 78, 85, 68, 81,  2, 72, 83, 15,  2, 51, 71,\n",
      "        68, 88,  2, 67, 72, 67, 77,  9, 83,  2, 83, 71, 72, 77, 74,  2, 83, 71,\n",
      "        68, 88,  2, 66, 78, 84, 75, 67,  2, 65, 68, 64, 81,  2, 72, 83,  2, 72,\n",
      "        69,  2, 64, 77, 88, 78, 77, 68,  2, 69, 78, 84, 77, 67,  2, 78, 84, 83,\n",
      "         2, 64, 65, 78, 84, 83,  2, 83, 71, 68,  2, 47, 78, 83, 83, 68, 81, 82,\n",
      "        15,  2, 44, 81, 82, 15,  2, 47, 78, 83])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f839d63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39, 64, 81, 81, 88,  2, 47, 78, 83])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845284ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([39]) the target is 64\n",
      "when input is tensor([39, 64]) the target is 81\n",
      "when input is tensor([39, 64, 81]) the target is 81\n",
      "when input is tensor([39, 64, 81, 81]) the target is 88\n",
      "when input is tensor([39, 64, 81, 81, 88]) the target is 2\n",
      "when input is tensor([39, 64, 81, 81, 88,  2]) the target is 47\n",
      "when input is tensor([39, 64, 81, 81, 88,  2, 47]) the target is 78\n",
      "when input is tensor([39, 64, 81, 81, 88,  2, 47, 78]) the target is 83\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59249c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[69,  2, 88, 78, 84, 15,  4,  0],\n",
      "        [65, 75, 68,  2, 69, 84, 77, 70],\n",
      "        [75, 75,  2, 72, 77, 83, 78,  2],\n",
      "        [ 2, 67, 72, 67, 77, 95, 83,  2]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2, 88, 78, 84, 15,  4,  0,  4],\n",
      "        [75, 68,  2, 69, 84, 77, 70, 72],\n",
      "        [75,  2, 72, 77, 83, 78,  2, 72],\n",
      "        [67, 72, 67, 77, 95, 83,  2, 67]])\n",
      "----------\n",
      "when input is [69] the target: 2\n",
      "when input is [69, 2] the target: 88\n",
      "when input is [69, 2, 88] the target: 78\n",
      "when input is [69, 2, 88, 78] the target: 84\n",
      "when input is [69, 2, 88, 78, 84] the target: 15\n",
      "when input is [69, 2, 88, 78, 84, 15] the target: 4\n",
      "when input is [69, 2, 88, 78, 84, 15, 4] the target: 0\n",
      "when input is [69, 2, 88, 78, 84, 15, 4, 0] the target: 4\n",
      "when input is [65] the target: 75\n",
      "when input is [65, 75] the target: 68\n",
      "when input is [65, 75, 68] the target: 2\n",
      "when input is [65, 75, 68, 2] the target: 69\n",
      "when input is [65, 75, 68, 2, 69] the target: 84\n",
      "when input is [65, 75, 68, 2, 69, 84] the target: 77\n",
      "when input is [65, 75, 68, 2, 69, 84, 77] the target: 70\n",
      "when input is [65, 75, 68, 2, 69, 84, 77, 70] the target: 72\n",
      "when input is [75] the target: 75\n",
      "when input is [75, 75] the target: 2\n",
      "when input is [75, 75, 2] the target: 72\n",
      "when input is [75, 75, 2, 72] the target: 77\n",
      "when input is [75, 75, 2, 72, 77] the target: 83\n",
      "when input is [75, 75, 2, 72, 77, 83] the target: 78\n",
      "when input is [75, 75, 2, 72, 77, 83, 78] the target: 2\n",
      "when input is [75, 75, 2, 72, 77, 83, 78, 2] the target: 72\n",
      "when input is [2] the target: 67\n",
      "when input is [2, 67] the target: 72\n",
      "when input is [2, 67, 72] the target: 67\n",
      "when input is [2, 67, 72, 67] the target: 77\n",
      "when input is [2, 67, 72, 67, 77] the target: 95\n",
      "when input is [2, 67, 72, 67, 77, 95] the target: 83\n",
      "when input is [2, 67, 72, 67, 77, 95, 83] the target: 2\n",
      "when input is [2, 67, 72, 67, 77, 95, 83, 2] the target: 67\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----------\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61bfa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "tensor(5.0269, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "sP2g­6c/M!xQ\u001f%-%*HRo/~kz­0-é(~K­./DYmp\n",
      "O$7sZXgo`\n",
      "KdaT(QEaQMYétU6dotARt&o;éP/gDo7ték6ZUa/&P&os2%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T , C)\n",
    "            targets = targets.view(B*T) #or -1\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits,dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "out, loss = m(xb, yb)\n",
    "print(out.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7dea256",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f44e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5120654106140137\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(50000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b5de17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'s, tifowad ay and f s a kesap de;\n",
      "\"\n",
      "\"So The tainen warit, t t ckevotou b. a he willexppid BBee s la fisthak w med od; w. ofee. he I'sin ch wasn ariaweapoolos s ty. l, Eat twoome yone. t. te ate.\n",
      "ste tothe\n",
      "\"\n",
      "\"I cto ar ly?\" thengofeofonineelathat g ty g Itothy?\" histh, rk!\" d Daceusg ly ff ­­ay \"GHack terinklerred hes pin Har ng wn, Hooay wh, Gofanedo st sf ble him t?\"­ marin minery Whaite larurreret tino sit. alailyf bokeaicchof ile vesarus menderemin,\"\n",
      "Lansond coremerlyoumok hemala ds t as Har \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dffd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
